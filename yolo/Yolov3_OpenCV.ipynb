{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO - You Only Look Once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import functools\n",
    "import time\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobieranie wag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('yolov3.weights'):\n",
    "    !wget https://pjreddie.com/media/files/yolov3.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('yolov3-tiny.weights'):\n",
    "    !wget https://pjreddie.com/media/files/yolov3-tiny.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie wag do modelu dostarczonego przez OpenCv.\n",
    "\n",
    "Do wyboru wagi oryginalne oraz wagi modelu uproszczonego - tiny-yolo, który kosztem jakości detekcji znacząco przyspiesza inferencję"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\") # Original yolov3\n",
    "# net = cv2.dnn.readNet(\"yolov3-tiny.weights\", \"yolov3-tiny.cfg\") #Tiny Yolo\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "outputlayers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wypisanie nazw klas obiektów rozpoznawanych przez model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes = []\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prapagate_input(frame):\n",
    "    blob = cv2.dnn.blobFromImage(frame,0.00392,(320,320),(0,0,0),True,crop=False)\n",
    "    net.setInput(blob)\n",
    "    return net.forward(outputlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_frame(video_capture, skip=5):\n",
    "    # pobieranie jedenj klatki na kilka, aby uniknąć opóźnień\n",
    "    for i in range(skip):\n",
    "        video_capture.read()\n",
    "    _,frame= video_capture.read()\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_bounding_boxes(inference_results, width, height):\n",
    "    class_ids=[]\n",
    "    confidences=[]\n",
    "    boxes=[]\n",
    "    for result in inference_results:\n",
    "        for detection in result:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.4:\n",
    "                #skalowanie znalezionych współrzędnych do przetwarzanego obrazu                 \n",
    "                center_x= int(detection[0]*width)\n",
    "                center_y= int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                #współrzędne prostokąta (bounding box'a)\n",
    "                x=int(center_x - w/2)\n",
    "                y=int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x,y,w,h]) \n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    return class_ids, confidences, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(boxes, indexes):\n",
    "    colors= np.random.uniform(0,255,size=(len(classes),3))\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x,y,w,h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence= confidences[i]\n",
    "            color = colors[class_ids[i]]\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),color,2)\n",
    "            cv2.putText(frame,label+\" \"+str(round(confidence,2)),(x,y+30),font,1,(255,255,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def put_fps_on_image(start_time):\n",
    "    elapsed_time = time.time() - start_time\n",
    "    fps=frame_id/elapsed_time\n",
    "    cv2.putText(frame,\"FPS:\"+str(round(fps,2)),(10,50),font,2,(0,0,0),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przekształcenia obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_90(img):\n",
    "    return cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(img):\n",
    "    return cv2.flip(img, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative(img):\n",
    "    return cv2.bitwise_not(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(img):\n",
    "    return cv2.blur(img,(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(transformations, img):\n",
    "    for transformation in transformations:\n",
    "        img = transformation(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zachęca się do przeprowadzenia eksperymentów, sprawdzających jak zachowa się model, gdy jako wejście otrzyma przekształcony obraz\n",
    "\n",
    "Należy odkomentować interesujące nas transformacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [\n",
    "#     grayscale,\n",
    "#     rotate_90,\n",
    "#     flip,\n",
    "#     negative,\n",
    "#     blur\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uruchomienie detekcji obrazów z kamery za pomocą Yolo \n",
    "Aby zamknąć okno należy wcisnąć ESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#inicjalizacja kamerki\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "start_time = time.time()\n",
    "frame_id = 0\n",
    "\n",
    "while True:\n",
    "    #Pobranie klatki z kamery     \n",
    "    frame = get_frame(video_capture)\n",
    "    frame = apply_transformations(transformations, frame)\n",
    "    frame_id+=1\n",
    "    height,width,channels = frame.shape\n",
    "    #Detekcja za pomocą Yolo\n",
    "    inference_results = prapagate_input(frame)\n",
    "\n",
    "    #Podział wynikowego wektora inferencji na bounding boxy\n",
    "    class_ids, confidences, boxes = get_bounding_boxes(inference_results, width, height)\n",
    "\n",
    "    # Użycie Non-Max-Supression aby zostawić tylko jeden bounding box per obiekt\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.6)\n",
    "\n",
    "    draw_bounding_boxes(boxes, indexes)  \n",
    "    put_fps_on_image(start_time)\n",
    "    \n",
    "    cv2.imshow(\"OpenCv_Yolov3\",frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    #ESC\n",
    "    if key == 27: \n",
    "        break\n",
    "    \n",
    "video_capture.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porównanie Yolo vs tiny-Yolo\n",
    "\n",
    "Wiersz jakość detekcji należy uzupełnić subiektywną opinią z przedziału [bardzo dobra, dobra, średnia, zła, bardzo zła] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                       |**Yolo**       |**tiny-Yolo** \t|\n",
    "| :-----------          | ------------- | ------------- |\n",
    "| **Fps**               | todo  | todo  |\n",
    "| **Rozmiar pliku wag** | todo  | todo  |\n",
    "| **Jakość detekcji**   | todo  | todo  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9a29d26e53bb4ad3abaee9f415aa2337"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
